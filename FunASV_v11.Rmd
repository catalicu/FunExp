---
title: "FunExp_v11"
author: "Dr CG"
date:"1/13/2023"
output: 
  html_document:
    toc: TRUE
---
# Taxon analysis for FunExp
Abbreviated code for figures 5a and 5b in FunExp Manuscript.

I will use the species rankins from FunASV_v8_taxAnalysis_abund-functB
Code is extracted from
FunASV_v11_taxAnalysis_time-abund_sorted

## Preparation
### Load libraries and establish a plotting theme
```{r message=FALSE}
# Libraries
library(ggplot2)
library(vegan)
library(dplyr)
library(plyr)
library(lme4)
library(nlme)
library(gridExtra)
library(reshape2)
library(car)
library(MASS)

# Plot themes
## With legend
Theme=theme_classic(base_size=11, base_family="Helvetica") +
	theme(axis.line = element_line(size = 1, colour = "black", linetype = "solid")) +theme(plot.title = element_text(size = 12))
## Without legends
Theme2=Theme+ theme(legend.position="none") + theme(panel.border=element_rect(fill=NA))
```

### Second, load the datasets: 

#### Obtain functional data
Import the tables and code from FunASV_v4_taxFunct2:
```{r}
ASVtable.fundiv=read.table('input_data/ASVtable_forGLM_FunExp12023-01-04.txt', header=TRUE)
  ASVtable.fundiv1=ASVtable.fundiv[,-1]
taxatable=read.table('input_data/taxtable_FunExp12023-01-04.txt', header=TRUE)

```

#### Obtain ranking data
Load the information on taxon classification according to their relationship with function (from FunASV_v8_taxAnalysis_abund-funct_B.R).
```{r}
ASVslope_sorted=read.table('input_data/ASVslope_sorted_FunExp12023-01-07.txt', header=TRUE)
```


## Species patterns
This analysis processes each species separately to establish the differential abundance behind the successional patterns in composition and diversity. 

### prepare datasets
Before melting, reduce the dataset to taxa that we were able to relate to function (in scritp v8)
```{r}
# select the columns that will go into the long format:
  # include treatment, leaf age, and taxa that were realted to function
ASVfor_melt=ASVtable.fundiv[,c(which(colnames(ASVtable.fundiv)%in%(ASVslope_sorted$ASVcode)),1387,1389)]
```



First you must join the ASV table and the metadata table in long format. Each datapoint (counts or rel abundance) should have a row now.
```{r}

	# Then use melt to go from the wide table format to the long table format. 
otumelt_fun=melt(ASVfor_melt, id=c("treatment", "leaf_age_weeks"))
length(names(otumelt_fun))
names(otumelt_fun)[(length(names(otumelt_fun))-1):length(names(otumelt_fun))]=c("ASVcode", "Abundance") # the last two columns will represent the ASV code an the abundance value 
head(otumelt_fun)
```

Clean the tax table to add tax information to the long version of the ASV table with metadata (otumelt)
```{r}
otumelt2=left_join(otumelt_fun, taxatable,  by='ASVcode')

# make sure the relative abundance column is numeric
otumelt2$Abundance=as.numeric(as.character(otumelt2$Abundance))

# remove rows with no information in the treatment and leaf age (where did these come from?)
otumelt3=otumelt2[-which(is.na(otumelt2$treatment)),]
head(otumelt3)
```

#### Generate list of ASVs with taxonomic and abundance data
Generate a list of unique family names in order of decreasing abundance	 (object: familylist3)
Also create a table with abundance per family (object: meanlist.fam3).
```{r}
ASVlist=unique(otumelt2$ASVcode)	
length(ASVlist)
# calculate means for abundance per taxon
ASVlist_means=ddply(otumelt2, .(ASVcode), summarize,  Abund=mean(Abundance, na.rm=TRUE))
ASVlist_means=ASVlist_means[order(ASVlist_means$Abund, decreasing=TRUE),]
ASVlist2=left_join(ASVlist_means, taxatable)
 
```

### Temporal trends of functional taxa

#### Do the most functional taxa increase over time?
ASV691 was identified as a low abundance taxon with the highest performance and classified as Rodobacter sp. 
```{r}
otumelt3_ASV691=otumelt3[which(otumelt3$ASVcode=='ASV691'),]
otumelt3_ASV691_w0=otumelt3_ASV691[-which(otumelt3_ASV691$Abundance==0),]
ggplot(otumelt3_ASV691_w0, aes(leaf_age_weeks, (Abundance+1))) + geom_point() + ylim(0,20) +xlim(0, 24)
```
#### Do the most abundant taxa increase over time?

This is the most abundant and frequent taxon:
ASV1 Enterobacteraceae
It was identified as having a significant negative relationship with function.

```{r}
otumelt3_ASV1=otumelt3[which(otumelt3$ASVcode=='ASV1'),]
otumelt3_ASV1_w0=otumelt3_ASV1#[-which(otumelt3_ASV1$Abundance==0),]
ggplot(otumelt3_ASV1_w0, aes(leaf_age_weeks, (Abundance+1))) + geom_point() +xlim(0, 24) + geom_smooth(method='lm', se=FALSE, color='black') + Theme + xlab('Leaf age (weeks)') + ylab('log(Abundance +1)')
```
#### Are there general trends of taxa over time?
Plot them all together to see general trends. this suggests:
* most abundant ones decrease a few remain constant. 
* some of the less aboundant increase with time
```{r}
ggplot(otumelt3, aes(leaf_age_weeks, log(Abundance+1))) + geom_jitter(aes(color=ASVcode), alpha=0.4) +xlim(0, 24) + geom_smooth(method='lm', se=FALSE, color='black') + theme(legend.position='none') + geom_smooth(method='lm', aes(color=ASVcode), se=FALSE) + Theme + theme(legend.position='none')
```

### Model selection: what model to use?
Check the data distribution. Throughout the top 10 abundant  taxa thee best model is consistency including the interaction between the leaf age and the treatment. 
```{r eval=FALSE}
#check distributions
i=2
ASVlist=ASVlist2$ASVcode
OTUdata=otumelt2[which(otumelt2$ASVcode%in%ASVlist[i]),]
  if (length(which(is.na(OTUdata$Relative_abundance)))>0){
  	OTUdata2=OTUdata[-which(is.na(OTUdata$Relative_abundance)),]} else { OTUdata2=OTUdata}
		  qqp(OTUdata2$Abundance+1, 'norm')
		  qqp(OTUdata2$Abundance+1, 'lnorm')
		   qqp(OTUdata2$Abundance+1, 't')
		    hist(OTUdata2$Abundance+1)
		    
		    poisson=fitdistr(OTUdata2$Abundance+1, 'Poisson')  
		   qqp(OTUdata2$Abundance+1, 'pois', lambda=poisson$estimate[1])
		   
		   binom=fitdistr(OTUdata2$Abundance+1, 'binom')  
		   qqp(OTUdata2$Abundance+1, 'pois', lambda=poisson$estimate[1]) 
		   
	lm_NULL=lm(Abundance ~  1 , data=OTUdata2)
	lm_model=lm(Abundance ~ leaf_age_weeks, data=OTUdata2)
		summary(lm_model)
		Anova(lm_model)
	glm_NULL=glm.nb(Abundance ~  1 , data=OTUdata2)
	glm_model=glm.nb(Abundance ~  leaf_age_weeks , data=OTUdata2)
	
		summary(glm_model)
		Anova(glm_model)

	AIC(lm_model,lm_NULL, glm_model,  glm_NULL) # the glm model is more fit.
```
### Iterative GLM model
Now build an iterative model function:
* glm (poisson distribution) vs null model
* Store the model's outputs and the comparison with the null. 
(I had a note about using the Gauss-Hermite quadrature GHQ method with one iteration but no idea what that is)
Possibilities: 
(Could also have if else statements to remove low abundance or occurrence)
(Could use a GLM negative binomial (glm.nb))

Input:
* long format dataset with ASV and metadata: otumel2
* list of taxa with number, DNA sequence, taxonomic affiliation and organized from more abundant to least abundant: ASVlist2

```{r eval=FALSE}
IterativeGLM1 <- function(long_data, ASVlist2){
  model.results.otuA=c() # store model coefficients and output
  model.evaluation.otuA=c() # store comparison between models
  
for (i in 1:length(ASVlist2$ASVcode)){
  # extract data
	OTUdata=otumelt2[which(otumelt2$ASVcode%in%ASVlist2$ASVcode[i]),] 
	OTUdata2=OTUdata 
			# GLM with Poisson distribution
			Mod1=glm.nb(Abundance ~ leaf_age_weeks, data=OTUdata2)
				Mod1.summary=summary(Mod1)
					Mod1.coeff=Mod1.summary$coefficients
			# Null model
			Mod1.null=glm.nb(Abundance ~ 1, data=OTUdata2)
				Mod1.aov=anova(Mod1, Mod1.null, test='Chisq')
		  # Comparison	
		  aic.model=AIC(Mod1,Mod1.null)
		# store coefficients
		coeff.full.model = data.frame((Mod1.summary$coefficients), 
		                              adj.p=p.adjust(Mod1.summary$coefficients[,2]), 
		                              ASVcode=rep(unique(OTUdata2$ASVcode), 2), 
		                              Family=rep(OTUdata2$Family[i],2) ,
		                              Genus=rep(OTUdata2$Genus[i],2), 
		                              ASVcode=rep(ASVlist2$ASVcode[i],2)) 
		# store comparison
		
		coeff.aov = data.frame(model=c(paste(unique(OTUdata2$ASVcode), 'null.model', sep='_'),
		                               paste(unique(OTUdata2$ASVcode), 'full.model', sep='_')), 
		                       resid.df=Mod1.aov[3], 
		                       resid.theta=Mod1.aov[2], 
		                       #deviance=Mod1.aov[[4]], 
		                       AIC=aic.model$AIC, 
		                       p.value=c('NA', (Mod1.aov$`Pr(Chi)`)[2]), 
		                       adj.p=c('NA', p.adjust(Mod1.aov$`Pr(Chi)`)[2]), 
		                       Family=rep(OTUdata2$Family[i],2) ,
		                       Genus=rep(OTUdata2$Genus[i],2), 
		                       ASVcode=rep(OTUdata2$ASVcode[i],2))		
		
		# format result table
	model.results.otuA=(rbind(model.results.otuA, coeff.full.model)) 			
	model.evaluation.otuA=(rbind(model.evaluation.otuA, coeff.aov))					
	
	  # print taxa number, family and genus as a way to track progress of the function: remove if >100 taxa
	print(paste(OTUdata$Family[i], OTUdata$Genus[i], i))
  }
dim(model.results.otuA) # check the dimensions
  
  # add names to the columns of the output tables
	names(model.results.otuA)=c('Estimate', 'Sdev', 'z.value', 'p.value', 'p.adjust', 'ASV2','Family', 'Genus', 'ASVcode')
  names(model.evaluation.otuA)=c('Model', 'Resid.dev', 'theta', 'AIC', 'p.value','adjust.p', 'Family', 'Genus', 'ASVcode')
  
  # store both data frames within a list
  model.results.output = list(coefficients=model.results.otuA, evaluation=model.evaluation.otuA)

return(model.results.output)
}
```

Test with the list of taxa ASVlist3. Notice that the last 375 taxa have zero abundances in this dataset after removing controls and outliers. These taxa are not included in the analysis. Thus only the 1000 most abundant taxa are included. 
```{r include=FALSE}
model.results.trial1=IterativeGLM1(otumelt2, ASVlist2[1:30,])
```

(this part was removed from the latest iteration) - will focus on the glm instead of the null comparison.
Clean  the output of the function: these tables will go to supplementary materials. 
```{r eval=FALSE}
models.coefficients1 = model.results.trial1$coefficients
models.evals1 = model.results.trial1$evaluation
```
And save
```{r}
outPATH='output_files/'
date=Sys.Date()
    glm.models.coeff = paste(outPATH, 'ASV_glm_time_subset_FunExp1', date,'.txt', sep='')
    glm.models.evals = paste(outPATH, 'ASV_glm_evals_FunExp1', date,'.txt', sep='')

	write.table(models.coefficients1, glm.models.coeff, sep="\t")
	write.table(models.evals1, glm.models.evals, sep="\t")
```

### ID taxa that increase with time from Iterative model
Can I identify which taxa are increasing with age relably to later test whether they are correlated with function?

```{r include=FALSE}
# create lists to store potential ASVs correlated with function
list_asv_slopePos.time=c()
list_asv_noslope.time=c()
list_asv_slopeNeg.time=c()

# list of ASV codes to go through:
ASVtime_names=ASVlist2$ASVcode

for (i in 1:length(ASVtime_names)){
  # check that the ASV is present in the dataset
  if (sum(which(models.coefficients1$ASVcode==ASVtime_names[i]))==0) { print(paste(ASVtime_names[i], 'ASV not found'))
    } else {
    # extract the slope estimate:
      ASVabund.estimate= models.coefficients1[which(models.coefficients1$ASVcode==ASVtime_names[i]),1][2]
    # extract the p value:
      ASVabund.p= models.coefficients1[which(models.coefficients1$ASVcode==ASVtime_names[i]),5][2]
      ASVcode= models.coefficients1[which(models.coefficients1$ASVcode==ASVtime_names[i]),8][2]
      ASVGenus= models.coefficients1[which(models.coefficients1$ASVcode==ASVtime_names[i]),6][2]
      
    # inform of progress:  
      print(paste('Progress:', i, ASVcode, ASVGenus))
    
    # check that output differs from NA
      if (is.na(ASVabund.p)) { 
          print(paste(ASVtime_names[i], 'p value was NA'))
          list_asv_noslope.time=rbind(list_asv_noslope.time, c(ASVtime_names[i], ASVabund.estimate, ASVabund.p))
                             } else {
        
    # Sort the taxa
      # if the taxa has a positive slope estimate and a significant adjusted p value -> accept and store ASVcode
        if (ASVabund.estimate > 0 && ASVabund.p < 0.05 ) {
          list_asv_slopePos.time=rbind(list_asv_slopePos.time, c(ASVtime_names[i], ASVabund.estimate, ASVabund.p))
            } else   { 
       # if the taxa has a negative slope estimate and a significant adjusted p value -> accept and store ASVcode
        if (ASVabund.estimate < 0 && ASVabund.p < 0.05 ) {
          list_asv_slopeNeg.time=rbind(list_asv_slopeNeg.time, c(ASVtime_names[i], ASVabund.estimate, ASVabund.p))
            } else {
       # store non significant and NA results ASV in noslope list
        list_asv_noslope.time=rbind(list_asv_noslope.time, c(ASVtime_names[i], ASVabund.estimate, ASVabund.p)) 
                   }
                    } 
                                }
                                }
        }

```

#### Edit the sorted tables and save
Change from matrix to data frame and add column names.
Focus on negative and positive slopes from here on. 
```{r}
list_asv_slopePos.time.df=data.frame(list_asv_slopePos.time)
  colnames(list_asv_slopePos.time.df)=c('ASVcode', 'ASVestimate', 'ASVp.value')
  listPos.rank.time=list_asv_slopePos.time.df[order(list_asv_slopePos.time.df$ASVestimate),]
  
list_asv_slopeNeg.time.df=data.frame(list_asv_slopeNeg.time)
  colnames(list_asv_slopeNeg.time.df)=c('ASVcode', 'ASVestimate', 'ASVp.value')
  listNegslope.rank.time=list_asv_slopeNeg.time.df[order(list_asv_slopeNeg.time.df$ASVestimate),]
  
list_asv_noslope.time.df=data.frame(list_asv_noslope.time)
  colnames(list_asv_noslope.time.df)=c('ASVcode', 'ASVestimate', 'ASVp.value')
  listnoslope.rank.time=list_asv_noslope.time.df[order(list_asv_noslope.time.df$ASVestimate),]
```

Merge the lists with their taxonomic affiliations
```{r}
listPos.rank_taxa.time=left_join(listPos.rank.time, taxatable)
listnoslope.rank_taxa.time=left_join(listnoslope.rank.time, taxatable)
listNeg.rank_taxa.time=left_join(listNegslope.rank.time, taxatable)

```
Save them as a single table
```{r}
 ASVslope.sorted.time=rbind(
    data.frame(Slope.time=rep('Positive',dim(listPos.rank_taxa.time)[1]), listPos.rank_taxa.time),
    data.frame(Slope.time=rep('Neutral',dim(listnoslope.rank_taxa.time)[1]), listnoslope.rank_taxa.time),
    data.frame(Slope.time=rep('Negative',dim(listNeg.rank_taxa.time)[1]), listNeg.rank_taxa.time))
    
ASVslope.sorted_path = paste(outPATH, 'ASVslope_sorted_time_FunExp1', date,'.txt', sep='')

	write.table(ASVslope.sorted.time, ASVslope.sorted_path, sep="\t")
```

### Compare ASV lists

```{r}
names(ASVslope.sorted.time)[3:4]=c('ASVestimate.time', 'ASVp.value.time')
Compare_asv_list=left_join(ASVslope_sorted, ASVslope.sorted.time)
Compare_asv_list$ASVestimate.time=as.numeric(Compare_asv_list$ASVestimate.time)
Compare_asv_list$ASVp.value.time=as.numeric(Compare_asv_list$ASVp.value.time)
```


#### compare time and function model results:
Plot estimates
```{r}
ggplot(Compare_asv_list, aes(ASVestimate, ASVestimate.time)) + geom_point(aes(color=Slope))
```
Plot pvalues
```{r}
ggplot(Compare_asv_list, aes(ASVp.value, ASVp.value.time)) + geom_point(aes(color=Slope, shape=Slope.time))
```
Plot pvalues
```{r}
ggplot(Compare_asv_list, aes(ASVp.value, ASVestimate)) + geom_point(aes(color=Slope, shape=Slope.time))
ggplot(Compare_asv_list, aes(ASVp.value.time, ASVestimate.time)) + geom_point(aes(color=Slope.time))
```
#### QUestions
Are there taxa with models significantly different than the null who are also showing positive slopes and p values bigger than 0.05?

## Track these taxa with respect to functional means
```{r}
# import the table output from FunASV_v5_taxFunct_means2
# it includes mean relative abundance, occurrence and function for each ASV
ASVrelabun.pa.fun=read.table('output_files/ASV_relabun_pa_fun_table_FunExp12022-12-21.txt', header=TRUE)
ASVrelabun.pa.fun$ASV1=rownames(ASVrelabun.pa.fun)

SelectTaxa_ASVrpf=ASVrelabun.pa.fun[which(ASVrelabun.pa.fun$ASV1%in%Compare_asv_list),]
```

Explore:
```{r}
# Funct vs frequency (occurrence)
ggplot(SelectTaxa_ASVrpf, aes((ASVfunRat), ASVpa.freq)) + geom_point(size=3) + Theme
# Histogram of function
ggplot(SelectTaxa_ASVrpf, aes(x=ASVfunRat)) + geom_histogram() +Theme
# relative abundance vs frequency (occurrence)
ggplot(SelectTaxa_ASVrpf, aes((ASVrel.abund), ASVpa.freq)) + geom_point(size=3) + Theme

```

## Track these taxa with respect to functional data
Import the tables and code from FunASV_v4_taxFunct2
```{r}
ASVtable.wnames.fundiv=read.table('output_files/ASVtable_forfunctPlots_FunExp12022-12-21.txt', header=TRUE)
ASVtable.wnames.fundiv_Select=ASVtable.wnames.fundiv[,c(which(names(ASVtable.wnames.fundiv)%in%Compare_asv_list),1359:1376)]
```



Explore with a GLM: try it out with one ASV
```{r}
# create list of ASV:
ASVfun_names=names(ASVtable.wnames.fundiv_Select)[1:140]
i=1 # select the first ASV
ASVdataFun=(ASVtable.wnames.fundiv_Select[,c(i,141:158)])
  # Rename the column for the selected taxa
  names(ASVdataFun2)[1]='ASVcode'
  # Remove lines with zero abundance
  ASVdataFun2=ASVdataFun[-which(ASVdataFun$ASVcode==0),] 
  # Remove lines with NA for W_Change (function)
  ASVdataFun3=ASVdataFun2[-which(is.na(ASVdataFun2$W_Change)),] 
    

  # Create a plot
    ggplot(ASVdataFun3, aes(log(ASVcode), W_Change)) + geom_point(aes(color=leaf_age_weeks, shape=treatment))
  
  mod.lm.fun=lm(W_Change~ASVcode, data=ASVdataFun3)
  mod.glm.fun.gaus=glm(W_Change~ASVcode, data=ASVdataFun3)
  mod.glm.fun.pois=glm(W_Change~ASVcode, data=ASVdataFun3, poisson(link='log'))
  mod.glmnb.fun=glm.nb(W_Change~ASVcode, data=ASVdataFun3)
AIC(mod.lm.fun, mod.glm.fun.gaus, mod.glm.fun.pois, mod.glmnb.fun)

```


Iterate the GLM
```{r echo=FALSE, include=FALSE}
# create list of ASV:
ASVfun_names=names(ASVtable.wnames.fundiv_Select)[1:140]

# create objects to store model results
model.glmFUN.results=c()

for (i in 1:length(ASVfun_names)) {
ASVdataFun=(ASVtable.wnames.fundiv_Select[,c(i,141:158)])
    names(ASVdataFun)[1]='ASVcode'
    if (length(which(ASVdataFun$ASVcode==0))>0) {
      ASVdataFun=ASVdataFun[-which(ASVdataFun$ASVcode==0),] } else {print('nope')}
    if (length(which(is.na(ASVdataFun$W_Change)))>0) {
      ASVdataFun=ASVdataFun[-which(is.na(ASVdataFun$W_Change)),] } else {print('nope2')}

Mod.fun1=lm(W_Change ~ ASVcode, data=ASVdataFun)
				Mod1.summary=summary(Mod.fun1)
					Mod1.coeff=Mod1.summary$coefficients
  # store coefficients
		coeff.full.model = data.frame((Mod1.summary$coefficients), 
		                              adj.p=p.adjust(Mod1.summary$coefficients[,2]), 
		                              ASVcode=rep(ASVfun_names[i],2)) 
	  model.glmFUN.results=(rbind(model.glmFUN.results, coeff.full.model)) 		
}
dim(model.glmFUN.results)
names(model.glmFUN.results)=c('Estimate', 'Sdev', 't.value', 'p.value', 'p.adjust', 'ASVcode')

```

#### Sort through the output tables:
Save one list with those taxa that have significant positive slopes with function, and one of those who do not. 
```{r}
# create list to store potential ASVs correlated with function
list_asv_slopePos.Fun=c()
list_asv_noslopePos.Fun=c()

for (i in 1:length(ASVfun_names)){
# extract the slope estimate:
ASVabund.estimate= model.glmFUN.results[which(model.glmFUN.results$ASVcode==ASVfun_names[i]),1][2]
# extract the p value:
ASVabund.p= model.glmFUN.results[which(model.glmFUN.results$ASVcode==ASVfun_names[i]),5][2]
ASVcode= model.glmFUN.results[which(model.glmFUN.results$ASVcode==ASVfun_names[i]),6][2]
if (is.nan(ASVabund.p)) {
  list_asv_noslopePos.Fun=c(list_asv_noslopePos.Fun, paste(ASVfun_names[i], 'NaN p.val'))
      } else {
# if the taxa has a negative slope estimate and a significant adjusted p value -> accept and store ASVcode
      if (ASVabund.estimate > 0 && ASVabund.p < 0.05 ) {list_asv_slopePos.Fun=c(list_asv_slopePos.Fun, ASVfun_names[i])
          } else   { list_asv_noslopePos.Fun=c(list_asv_noslopePos.Fun, ASVfun_names[i])}
              }
                                  }
length(list_asv_slopePos.Fun)
length(list_asv_noslopePos.Fun)

```


Merge the lists with their taxonomic affiliations
```{r}
taxa_asv_slopePos.Fun=taxatable[which(taxatable$ASV1%in%list_asv_slopePos.Fun),]
taxa_asv_noslopePos.Fun=taxatable[which(taxatable$ASV1%in%list_asv_noslopePos.Fun),]
```


#### Plots for positive taxa:
create a for loop for the figures.
```{r}
# create objects for the ASV code and the taxnames. 
  # this is probably not required, but for now it keeps things organized
ASVfun_names_pos=taxa_asv_slopePos.Fun$ASV1
ASVfun_taxnames_pos=taxa_asv_slopePos.Fun$Genus
ASVdata_forPosPlots=ASVtable.wnames.fundiv_Select[,c(which(names(ASVtable.wnames.fundiv_Select)%in%ASVfun_names_pos),141:158)]

# create an object to store the figures
ASVfun_figs=c()

for (i in 1:length(ASVfun_names_pos)) {	
      # select the dat
    figdata_fun=(ASVdata_forPosPlots[,c(i,28:45)])
     names(figdata_fun)[1]='ASVcode'
    if (length(which(figdata_fun$ASVcode==0))>0) {
      figdata_fun=figdata_fun[-which(figdata_fun$ASVcode==0),] } 
    if (length(which(is.na(figdata_fun$W_Change)))>0) {
      figdata_fun=figdata_fun[-which(is.na(figdata_fun$W_Change)),] } 
     
		  # Create a plot
    fig=ggplot(figdata_fun, aes(log(ASVcode), W_Change)) + geom_point(aes(color=leaf_age_weeks, shape=treatment)) + 
      Theme + ggtitle(ASVfun_taxnames_pos[i]) + theme(legend.position='none') +stat_smooth(method='lm', se=FALSE, color='black', size=0.5, linetype='dashed')
  ASVfun_figs[[i]]=fig
}
```

Explore the figures
```{r}
posFigs1=arrangeGrob(ASVfun_figs[[1]],ASVfun_figs[[2]],ASVfun_figs[[3]],ASVfun_figs[[4]],ASVfun_figs[[5]],ASVfun_figs[[6]], ncol=3)
plot(posFigs1)
```

Explore the figures2
```{r}
posFigs2=arrangeGrob(ASVfun_figs[[7]],ASVfun_figs[[8]],ASVfun_figs[[9]],ASVfun_figs[[10]],ASVfun_figs[[11]],ASVfun_figs[[12]], ncol=3)
plot(posFigs2)
```



Explore the figures3
```{r}
posFigs3=arrangeGrob(ASVfun_figs[[13]],ASVfun_figs[[14]],ASVfun_figs[[15]],ASVfun_figs[[16]],ASVfun_figs[[17]],ASVfun_figs[[18]], ncol=3)
plot(posFigs3)
```